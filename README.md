# CEREAL-X

# 🥣 협동로봇 기반 무인 시리얼 카페 시스템

**로봇 플랫폼:** Doosan Robotics E0509  
**키워드:** ROS2, 협동로봇, YOLO, Point Cloud, LLM API, 음성 인터페이스, 적응형 그리핑

---

## 1. 프로젝트 개요 (Overview)

이 프로젝트는 협동로봇(E0509)과 멀티모달 AI를 활용하여  
**무인 시리얼 카페의 주문·제조·제공·간단한 청소까지 자동화**하는 것을 목표로 한다.

로봇은 다음과 같은 역할을 수행한다.

- 키오스크 앞 고객 인식
- 음성 기반 메뉴 주문 수신
- 컵 위치/유무 인식 및 중복 서빙 방지
- 시리얼 제조 및 전달
- 대기 시간(Idle) 시 테이블 위 잔여 컵/쓰레기 정리

---

## 2. 시스템 구성 (System Architecture)

### 2.1 하드웨어 구성
<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/f0f17613-b35e-417b-ac5f-bc5ea34aa5ac" />

### 2.2 소프트웨어 구성
<img width="1280" height="720" alt="Image" src="https://github.com/user-attachments/assets/7fd34d4b-4568-49a8-a694-9327ad0a9c0d" />

- **ROS2 (Humble/Foxy 등)**  
  - 주문 시퀀스 제어 노드
  - 포인트 클라우드 기반 물체 감지 노드
  - YOLO 기반 객체 인식 노드
  - 로봇팔 제어 및 그리퍼 제어 노드
- **AI 모델**
  - YOLO: 사람/컵/시리얼 컵 검출
  - LLM API: 상황 분석, 음성 주문 처리, 안내 문구 생성
- **통신**
  - Modbus RTU/TCP: 그리퍼 전류값 읽기 및 제어
  - ROS2 Topic / Service / Action: 로봇 상태 및 시퀀스 관리
- **음성 입출력**
  - openAI realtimeGPT api기반 실시간 대화형 주문 
---

## 3. 주요 기능 (Core Features)

### 3.1 고객 인식 및 음성 주문 처리
<img width="400" height="400" alt="Image" src="https://github.com/user-attachments/assets/2dd71ea1-744b-48e2-8b5c-9d1abe743dae" 
  
- 키오스크 앞 영역에서 **YOLO 기반 사람 검출**을 수행.
- 사람이 감지되면:
  - 카메라 이미지 + 상황 정보를 LLM API로 전달
  - “ 개인 컵 소지 유무 / 연령대 및 성별” 등을 추론
  - LLM이 생성한 안내 멘트 출력
- 이후 **음성 기반 주문(realtime api)** 으로 메뉴 선택 및 옵션 지정.

---

### 3.2 ROS2 기반 자동 제조 시퀀스

- 주문이 확정되면 ROS2 상에서 다음 상태를 순차적으로 진행:

  1. 컵 픽업/준비
  2. 디스펜서 위치로 이동
  3. 시리얼/우유 디스펜싱
  4. 픽업 존으로 이동 및 제공

- 각 단계는 ROS2 Action/Service로 캡슐화하여  
  **“주문 → 제조 → 서빙” 전체 플로우를 완전 자동화된 시퀀스로 구성.**

---

### 3.3 컵 유무/위치 인식 및 중복 서빙 방지
<img width="400" height="400" alt="Image" src="https://github.com/user-attachments/assets/a9b64a25-3837-4220-80ec-ff47f71ef8fc" />

- Depth + YOLO 기반으로 **픽업 위치의 컵 유무 및 위치/자세를 인식.**
- 로봇 제조 시퀀스 중:
  - **픽업 지점에 기존 컵이 감지될 경우**, 현재 주문 시퀀스를 자동 중단.
  - 시리얼이 수령되기 전까지 추가 제조를 잠시 보류함.
- 이를 통해:
  - **중복 서빙 방지**
  - **로봇-컵 충돌 리스크 감소**
---

### 3.4 작업 공간 모니터링 및 Idle-State Cleaning
<img width="597" height="368" alt="Image" src="https://github.com/user-attachments/assets/7c014f26-930f-459d-89ac-5181cdc9260c" />
- 로봇이 작업 중이 아닐 때(Idle)에는  
  **포인트 클라우드 기반 테이블(WS) 감시 모드**로 전환.

- 동작 구조:
  1. 현재 작업 공간(Point Cloud) 스냅샷 저장
  2. 일정 주기마다 새 Point Cloud와 비교 → **새로 등장한 물체 감지**
  3. 새 물체가 일정 시간 이상 존재하면 “정리 대상”으로 판단
  4. LLM/VLM을 통해 물체 종류를 추론 (컵, 쓰레기 등)
  5. 미리 정의된 정리 동작(Trash bin, 정리 위치 등)으로 로봇이 이동하여 치우기
<img width="400" height="400" alt="Image" src="https://github.com/user-attachments/assets/c7393e9d-2f20-466f-ae31-2348d15b2882" />

- 테스트 환경 기준:
  - **새 물체 감지 및 정리 시퀀스 성공률 ~95%** 수준으로 동작.
---

### 3.5 적응형 그리핑 (Adaptive Grasping)

- 그리퍼는 **“잡기/놓기” 명령만 전달하는 방식으로 동작.**,  
- 내부 구현:
  - Modbus를 통해 그리퍼 내부 RAM의 **전류 RAW 데이터**를 직접 읽음
  - 수신한 바이트 배열을 decimal 값으로 파싱
  - 전류 변화량이 임계값 이상이면 “물체 접촉/파지 완료”로 판단
- 이를 통해:
  - 물체 크기와 상관없이 **하나의 그리핑 로직으로 다양한 컵을 파지** 가능
  - 유연한 그리핑 제어 가능
---

### 3.6 LLM-to-Robot 인터페이스

- LLM 출력은 자연어 문장 형식이므로, 이를 그대로 로봇에게 사용할 수 없음.
- 이를 해결하기 위해:
  - LLM 응답을 **미리 정의된 Action Token** 집합으로 맵핑
    - 예: `"MOVE_TO_PICKUP"`, `"CLEAN_TABLE"`, `"WAIT_FOR_CUSTOMER"`, …
  - ROS2 노드에서 이 토큰을 해석해 실제 로봇 액션 시퀀스로 변환.
- 결과적으로:
  - **“인지(vision) → 판단(LLM) → 제어(ROS2)”가 하나의 폐루프**로 동작하는 구조를 구현.

---

## 4. 동작 시나리오 (Operation Flow)

1. 고객이 키오스크 앞에 서면 카메라가 사람을 인식.
2. LLM이 상황을 분석하고, 인사 및 주문 안내 멘트 출력.
3. 고객 음성 → LLM → 메뉴/옵션 파싱.
4. 주문 확정 후, ROS2 기반 제조 시퀀스 시작.
5. 픽업 존에 기존 컵이 있는 경우:
   - 시퀀스 중단.
6. 유휴 시간에는 테이블 위 잔여 컵/쓰레기 감지:
   - 감지 → 분류 → 로봇이 정리 동작 수행.
---

## 5. 실험 및 성과 (Results)

> 아래 수치는 내부 테스트 환경에서의 기준값이며,  
> 상용 환경에서는 추가 검증이 필요함.

- **자동 주문 처리 성공률:**  
  - 고객 인식 → 음성 주문 → 주문 확정까지 전체 플로우 기준  
  - 약 **90%** 수준 성공 (인식 실패/잡음 환경 제외)

- **픽업 존 컵 중복 서빙 방지:**  
  - 테스트 케이스 기준, 이미 컵이 있는 상태에서  
    추가 제조가 진행된 경우 없음 (중복 서빙 방지 100% 달성)

- **Idle-State Cleaning 성공률:**  
  - 다양한 컵/쓰레기 배치 조건에서  
  - 새 물체 감지 + 정리 시퀀스 성공률 **95% 이상**

---

## 6. 한계 및 향후 발전 방향 (Limitations & Future Work)

### 6.1 현재 한계

- 조명 변화, 복잡한 배경에서의 인식 안정성 제한  
- 완전한 상용 수준이 아닌 **프로토타입/실증 단계**  
- LLM 응답 지연 시, 실시간성에 제약 발생 가능  
- 안전규정(인간-로봇 협동 구역)까지 포함한 상용 인증 단계는 미진행

### 6.2 향후 계획

- 다양한 환경(실제 카페, 조명 변화, 다중 사람)에서의 인식 성능 검증
- 로봇 동작 시 안전영역 감지 및 비상 정지 로직 고도화
- 모바일 베이스를 결합한 **“매장 전체 관리 로봇”** 방향으로 확장
- VLA/VLM 기반 정책과 결합해 더 복합적인 정리/세팅 작업으로 확장

---



# ✅ END OF README
